{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":["pOskyz0k7VZl","6QFKxr6o7VZ3"],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2doAJA_i7VXY","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","%reload_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBktLkwA-bxb","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Sa4T9dh_ZYF","colab_type":"code","colab":{}},"source":["!pip install pretrainedmodels\n","!pip install bcolz\n","!pip install isoweek\n","!pip install pandas_summary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xfYjaHca7g1P","colab_type":"code","colab":{}},"source":["# %cd 'drive/My Drive/SRP/Project/chestX-ray-14/src'\n","# %cd ../\n","#always be in src\n","!pwd\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDBhVZCmMXvh","colab_type":"code","colab":{}},"source":["!git commit -a -m \"updated test.ipynb\"\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pB8K61pv7VXm","colab_type":"code","colab":{}},"source":["# Fix: DataLoader causing `RuntimeError: received 0 items of ancdata`\n","# set ulimit top higher, \n","# !ulimit -n 4096 # no help, need to run outside and then start jupyter\n","# !ulimit -n\n","# 2048: e: 931 die\n","# torch.multiprocessing.set_sharing_strategy("],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fle2kNX97VXt","colab_type":"code","colab":{}},"source":["from chexnet import ChexNet\n","from unet import Unet\n","from dataset import ChestXray14Dataset\n","from transform import tta\n","from metrics import aucs\n","from constant import CLASS_NAMES, IMAGENET_MEAN, IMAGENET_STD\n","from fastai.conv_learner import *\n","\n","from matplotlib.patches import Patch\n","import pandas as pd\n","import skimage\n","from scipy import ndimage\n","from pathlib import Path\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset\n","import torch\n","import torchvision.transforms as transforms\n","from sklearn.metrics import roc_curve, auc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sP2e9SP7VX2","colab_type":"code","colab":{}},"source":["PATH = Path('dir')\n","IMAGE_DN = 'test_list_images'\n","CSV_FILE = 'test_list.csv'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"___gs-PI7VX7","colab_type":"code","colab":{}},"source":["chexnet_model = 'models'#'20180429-130928'\n","chexnet = ChexNet(trained=True, model_name=chexnet_model).cuda()\n","chexnet.eval();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxIMvHCQ7VYA","colab_type":"code","colab":{}},"source":["normalize = transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n","toTensor = transforms.ToTensor()\n","to_pil = transforms.ToPILImage()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iukaEX6i7VYI","colab_type":"text"},"source":["# Test one stage"]},{"cell_type":"code","metadata":{"id":"6Sj96lsl7VYJ","colab_type":"code","colab":{}},"source":["def get_test_dl(sz, bs, tfm):\n","    df = pd.read_csv(PATH/CSV_FILE, header=None, sep=' ')\n","    image_names = df.iloc[:, 0].values\n","    labels = df.iloc[:, 1:].values\n","    dataset = ChestXray14Dataset(image_names, labels, tfm, PATH/IMAGE_DN, sz, percentage=1)\n","    return DataLoader(dataset, bs, shuffle=True, num_workers=6)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4A7_OXGm7VYP","colab_type":"code","colab":{}},"source":["def test(model, dl, tta=False):\n","    targets = []\n","    preds = []\n","\n","    for image, target in dl:\n","        if tta:\n","            bs, cs, c, h, w = image.shape\n","            image = image.view(-1, c, h, w)\n","            \n","        pred = model(Variable(image.cuda()))\n","        if tta:\n","            pred = pred.view(bs, cs, -1).mean(1)\n","            \n","        targets.append(target.detach().cpu()) # detach remove this tensor from computation graph\n","        preds.append(pred.detach().cpu()) # if not call -> gpu memory leak since it still hold reference to computation graph\n","\n","    targets = torch.cat(targets)\n","    preds = torch.cat(preds)\n","\n","    all_aucs = aucs(torch.sigmoid(preds), targets)\n","    avg_auc = torch.mean(all_aucs)\n","    print(f'The average AUROC is {avg_auc:.3}')\n","    for i in range(14):\n","        print(f'The AUROC of {CLASS_NAMES[i]} is {all_aucs[i]:.3}')\n","    return targets, preds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8C2AVG5r7VYV","colab_type":"text"},"source":["## One crop"]},{"cell_type":"code","metadata":{"id":"iPAxLhDp7VYX","colab_type":"code","colab":{}},"source":["tfm = transforms.Compose([\n","    transforms.Resize(224),\n","    toTensor,\n","    normalize\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b1rDC3H7VYd","colab_type":"code","colab":{}},"source":["dl = get_test_dl(224, 16, tfm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kHK2gQFGfYGq","colab_type":"code","colab":{}},"source":["test(chexnet, dl)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jh5ZicnT24HL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBctgzvm7VYq","colab_type":"text"},"source":["## Five Crop "]},{"cell_type":"code","metadata":{"id":"WyNjEe707VYr","colab_type":"code","colab":{}},"source":["tfm = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.FiveCrop(224),\n","    transforms.Lambda(lambda crops: torch.stack([toTensor(crop) for crop in crops])),\n","    transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"4Veq03Rg7VYw","colab_type":"code","colab":{}},"source":["dl = get_test_dl(224, 4, tfm)\n","test(chexnet, dl, tta=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E7A2PIbi7VY5","colab_type":"text"},"source":["## Ten Crop"]},{"cell_type":"code","metadata":{"id":"cKtuPhPq7VY6","colab_type":"code","colab":{}},"source":["tfm = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.TenCrop(224),\n","    transforms.Lambda(lambda crops: torch.stack([toTensor(crop) for crop in crops])),\n","    transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8WQXoMl7VY-","colab_type":"code","colab":{}},"source":["dl = get_test_dl(224, 2, tfm)\n","dl"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-5k0DOGlXYR","colab_type":"code","colab":{}},"source":["\n","test(dl, tta=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eo8rdDlt7VZG","colab_type":"text"},"source":["# Segmentation"]},{"cell_type":"code","metadata":{"id":"xt14lEkA7VZH","colab_type":"code","colab":{}},"source":["# Only for segmented case\n","class TestChestXray14Dataset(Dataset): \n","    '''\n","    Get image for train, validate and test base on NIH split\n","    '''\n","\n","    def __init__(self, image_names, labels, transform, path, size, percentage=0.1, segmented_dict=None):\n","        self.labels = labels\n","        self.percentage = percentage\n","        self.size = size\n","        self.image_names = image_names\n","        self.path = path\n","        self.transform = transform\n","        self.segmented_dict = segmented_dict\n","        \n","    def __getitem__(self, index):\n","        image_file = self.path/self.image_names[index]\n","        image = Image.open(image_file).convert('RGB') # 1 channel segmented_dictge\n","        coords = self.segmented_dict[self.image_names[index]].split(' ')\n","        bb = list(map(lambda x: int(x), coords))\n","        image = image.crop(bb)\n","        label = self.labels[index]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, torch.FloatTensor(label)\n","\n","    def __len__(self):\n","        return int(self.image_names.shape[0] * self.percentage)\n","\n","    @property\n","    def sz(self):\n","        # fastai compatible: learn.summary()\n","        return self.size"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HK9ORRNp7VZM","colab_type":"code","colab":{}},"source":["def get_segmented_test_dl(sz, bs, tfm, segmented_file):\n","    df = pd.read_csv(PATH/CSV_FILE, header=None, sep=' ')\n","    image_names = df.iloc[:, 0].values\n","    labels = df.iloc[:, 1:].values\n","    with open(PATH/segmented_file, 'rb') as f:\n","        d = pickle.load(f)\n","    dataset = TestChestXray14Dataset(image_names, labels, tfm, PATH/IMAGE_DN, sz, percentage=1, segmented_dict=d)\n","    return DataLoader(dataset, bs, num_workers=6)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1sgWi047VZQ","colab_type":"code","colab":{}},"source":["def test_two_stage(dl, tta=False):\n","    targets = []\n","    preds = []\n","\n","    for image, target in dl:\n","#         imgs = []\n","#         for img in image:\n","#             img = to_pil(img)\n","#             img_v = V(unet_tfm(img)[None])\n","#             py = torch.sigmoid(segmentor(V(img_v)))\n","#             py = (py[0].cpu() > 0.5).type(torch.FloatTensor)\n","#             labels = skimage.measure.label(py[0].numpy())\n","#             mask = np.logical_or(labels==2, labels==1).astype(np.float32) # left nd right lung, 0 for background\n","#             mask = cv2.resize(mask, (1024, 1024))\n","#             slice_y, slice_x = ndimage.find_objects(mask, 1)[0]\n","#             img = img.crop((slice_x.start, slice_y.start, slice_x.stop, slice_y.stop))\n","#             img = chexnet_tfm(img)\n","#             imgs.append(img)\n","#         imgs = torch.stack(imgs)\n","\n","        if tta:\n","            bs, cs, c, h, w = image.shape\n","            image = image.view(-1, c, h, w)\n","            \n","        pred = chexnet(Variable(image.cuda()))\n","        \n","        if tta:\n","            pred = pred.view(bs, cs, -1).mean(1)\n","            \n","        targets.append(target.detach().cpu()) # detach remove this tensor from computation graph\n","        preds.append(pred.detach().cpu()) # if not call -> gpu memory leak since it still hold reference to computation graph\n","\n","    targets = torch.cat(targets)\n","    preds = torch.cat(preds)\n","\n","    all_aucs = aucs(torch.sigmoid(preds), targets)\n","    avg_auc = torch.mean(all_aucs)\n","    print(f'The average AUROC is {avg_auc:.3}')\n","    for i in range(14):\n","        print(f'The AUROC of {CLASS_NAMES[i]} is {all_aucs[i]:.3}')\n","    return targets, preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYZNuBv37VZT","colab_type":"code","colab":{}},"source":["chexnet_tfm = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    toTensor,\n","    normalize\n","])\n","    \n","dl = get_segmented_test_dl(256, 16, chexnet_tfm, 'cut_all.pickle')\n","test_two_stage(dl, tta=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"hOi9LvZO7VZa","colab_type":"code","colab":{}},"source":["chexnet_tta_tfm = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.FiveCrop(224),\n","    transforms.Lambda(lambda crops: torch.stack([toTensor(crop) for crop in crops])),\n","    transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n","])\n","\n","dl = get_segmented_test_dl(256, 4, chexnet_tta_tfm, 'cut_all.pickle')\n","test_two_stage(dl, tta=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rV6YUQs7VZg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3iGwLuBd7VZj","colab_type":"text"},"source":["# ROC analysis"]},{"cell_type":"markdown","metadata":{"id":"pOskyz0k7VZl","colab_type":"text"},"source":["### 1 stage vs 2 stage"]},{"cell_type":"code","metadata":{"id":"quW0mYHb7VZm","colab_type":"code","colab":{}},"source":["# 1 stage\n","dl = get_test_dl(224, 16, tfm)\n","one_stage_targets, one_stage_preds = test(chexnet, dl)\n","one_stage_roc = {}\n","for i in range(len(CLASS_NAMES)):\n","    one_stage_roc[CLASS_NAMES[i]] = roc_curve(to_np(one_stage_targets[:, i]), to_np(one_stage_preds[:, i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3BKybcim7VZu","colab_type":"code","colab":{}},"source":["# 2 stage\n","chexnet_tfm = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    toTensor,\n","    normalize\n","])\n","    \n","dl = get_segmented_test_dl(256, 16, chexnet_tfm, 'cut_all.pickle')\n","two_stage_targets, two_stage_preds = test_two_stage(dl, tta=False)\n","two_stage_roc = {}\n","for i in range(len(CLASS_NAMES)):\n","    two_stage_roc[CLASS_NAMES[i]] = roc_curve(to_np(two_stage_targets[:, i]), to_np(two_stage_preds[:, i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsVzVOKO7VZy","colab_type":"code","colab":{}},"source":["fig, axes = plt.subplots(3, 5, figsize=(20, 14))\n","for i, ax in enumerate(axes.flat):\n","    if i == 14:\n","        ax.plot(0, 0, c='r', label='one stage')\n","        ax.plot(0, 0, c='b', label='two stage')\n","        ax.legend( loc='center')\n","        ax.set_axis_off()\n","        break\n","    cn = CLASS_NAMES[i]\n","    \n","    # one stage\n","    fpr, tpr, threshold = one_stage_roc[cn]\n","    one_stage_auc = auc(fpr, tpr)\n","    one_stage_artist = ax.plot(fpr, tpr , c='r', label=f'AUC={one_stage_auc:0.3}')\n","    \n","    # two stage\n","    fpr, tpr, threshold = two_stage_roc[cn]\n","    two_stage_auc = auc(fpr, tpr)\n","    two_stage_artist = ax.plot(fpr, tpr, c='b', label=f'AUC={two_stage_auc:.3}')\n","    \n","    # enhance\n","    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","    ax.set_xlim([0.0, 1.0])\n","    ax.set_ylim([0.0, 1.05])\n","    ax.set_aspect('equal', 'box')\n","    ax.set_title(cn)\n","    ax.legend(loc='lower right')\n","\n","fig.text(0.5, 0.1, '1-specificity', ha='center', fontsize=20)\n","fig.text(0.095, 0.5, 'sensitivity', va='center', rotation='vertical', fontsize=20)\n","\n","plt.subplots_adjust(hspace=0.0001)\n","fig.savefig('two_stage_roc.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6QFKxr6o7VZ3","colab_type":"text"},"source":["### resnet vs densenet"]},{"cell_type":"code","metadata":{"id":"ALpMbcVy7VZ4","colab_type":"code","colab":{}},"source":["from models.resnet import Resnet\n","\n","MODEL_FILE = '/mnt/data/xray-thesis/models/resnet/resnet50/20180501-212649/model.path.tar'\n","d = torch.load(MODEL_FILE)\n","model_state = d['state_dict']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzgthRow7VZ7","colab_type":"code","colab":{}},"source":["resnet = Resnet('resnet50').cuda()\n","resnet.load_state_dict(model_state)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"69-6XbIF7VZ_","colab_type":"code","colab":{}},"source":["dl = get_test_dl(224, 16, tfm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-li5pc_n7VaC","colab_type":"code","colab":{}},"source":["# resnet\n","resnet_targets, resnet_preds = test(resnet, dl)\n","resnet_roc = {}\n","for i in range(len(CLASS_NAMES)):\n","    resnet_roc[CLASS_NAMES[i]] = roc_curve(to_np(resnet_targets[:, i]), to_np(resnet_preds[:, i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmdWjFot7VaG","colab_type":"code","colab":{}},"source":["# densnet\n","densenet_targets, densenet_preds = test(chexnet, dl)\n","densenet_roc = {}\n","for i in range(len(CLASS_NAMES)):\n","    densenet_roc[CLASS_NAMES[i]] = roc_curve(to_np(densenet_targets[:, i]), to_np(densenet_preds[:, i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GIVTwO1B7VaK","colab_type":"code","colab":{}},"source":["fig, axes = plt.subplots(3, 5, figsize=(20, 14))\n","for i, ax in enumerate(axes.flat):\n","    if i == 14:\n","        ax.plot(0, 0, c='r', label='resnet-50')\n","        ax.plot(0, 0, c='b', label='densenet-121')\n","        ax.legend( loc='center')\n","        ax.set_axis_off()\n","        break\n","    cn = CLASS_NAMES[i]\n","    \n","    # resnet\n","    fpr, tpr, threshold = resnet_roc[cn]\n","    resnet_auc = auc(fpr, tpr)\n","    ax.plot(fpr, tpr , c='r', label=f'AUC={resnet_auc:.3}')\n","    \n","    # densenet\n","    fpr, tpr, threshold = densenet_roc[cn]\n","    densenet_auc = auc(fpr, tpr)\n","    ax.plot(fpr, tpr, c='b', label=f'AUC={densenet_auc:.3}')\n","    \n","    # enhance\n","    ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","    ax.set_xlim([0.0, 1.0])\n","    ax.set_ylim([0.0, 1.05])\n","    ax.set_aspect('equal', 'box')\n","    ax.set_title(cn)\n","    ax.legend(loc='lower right')\n","\n","fig.text(0.5, 0.1, '1-specificity', ha='center', fontsize=20)\n","fig.text(0.095, 0.5, 'sensitivity', va='center', rotation='vertical', fontsize=20)\n","\n","plt.subplots_adjust(hspace=0.0001)\n","fig.savefig('res_dense_roc.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffrVcTYf7VaP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}